{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset and setup the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import os \n",
    "\n",
    "os.environ['JAVA_HOME']=\"/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--master local[2] pyspark-shell\"\n",
    "\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/labelled_dataset.csv.gz\"\n",
    "raw_data = sc.textFile(data_file).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(data_file,header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'txt']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'txt'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- txt: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label='ham', txt='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n",
      "\n",
      "\n",
      "Row(label='ham', txt='Ok lar... Joking wif u oni...')\n",
      "\n",
      "\n",
      "Row(label='spam', txt=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\")\n",
      "\n",
      "\n",
      "Row(label='ham', txt='U dun say so early hor... U c already then say...')\n",
      "\n",
      "\n",
      "Row(label='ham', txt=\"Nah I don't think he goes to usf, he lives around here though\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Didn't strictly need a for loop, could have just then head()\n",
    "for row in df.head(5):\n",
    "    print(row)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------------+\n",
      "|summary|               label|               txt|\n",
      "+-------+--------------------+------------------+\n",
      "|  count|             1970119|            840730|\n",
      "|   mean|            Infinity|1023.1263393359594|\n",
      "| stddev|                 NaN|  8450.10290912209|\n",
      "|    min|                   !|                  |\n",
      "|    max|⸪ Great Allowance...|        ”” said he|\n",
      "+-------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "877"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"label == 'spam'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"label == 'books'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48927271/count-number-of-words-in-a-spark-dataframe\n",
    "import pyspark.sql.functions as f\n",
    "data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+\n",
      "|label|                 txt|wordCount|\n",
      "+-----+--------------------+---------+\n",
      "|  ham|Go until jurong p...|       20|\n",
      "|  ham|Ok lar... Joking ...|        6|\n",
      "| spam|Free entry in 2 a...|       28|\n",
      "|  ham|U dun say so earl...|       11|\n",
      "|  ham|Nah I don't think...|       13|\n",
      "| spam|FreeMsg Hey there...|       32|\n",
      "|  ham|Even my brother i...|       16|\n",
      "|  ham|As per your reque...|       26|\n",
      "| spam|WINNER!! As a val...|       26|\n",
      "| spam|Had your mobile 1...|       29|\n",
      "|  ham|I'm gonna be home...|       21|\n",
      "| spam|SIX chances to wi...|       26|\n",
      "| spam|URGENT! You have ...|       26|\n",
      "|  ham|I've been searchi...|       37|\n",
      "|  ham|I HAVE A DATE ON ...|        8|\n",
      "| spam|XXXMobileMovieClu...|       19|\n",
      "|  ham|Oh k...i'm watchi...|        4|\n",
      "|  ham|Eh u remember how...|       19|\n",
      "|  ham|Fine if thatåÕs t...|       13|\n",
      "| spam|England v Macedon...|       24|\n",
      "+-----+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word count for each row\n",
    "df = df.withColumn('wordCount', f.size(f.split(f.col('txt'), ' ')))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(wordCount)=5584925)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total word\n",
    "df.select(f.sum('wordCount')).collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see what type df is\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='ham', txt='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', wordCount=20),\n",
       " Row(label='ham', txt='Ok lar... Joking wif u oni...', wordCount=6),\n",
       " Row(label='spam', txt=\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", wordCount=28),\n",
       " Row(label='ham', txt='U dun say so early hor... U c already then say...', wordCount=11),\n",
       " Row(label='ham', txt=\"Nah I don't think he goes to usf, he lives around here though\", wordCount=13)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 row\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+\n",
      "|label|                 txt|wordCount|\n",
      "+-----+--------------------+---------+\n",
      "|  ham|Go until jurong p...|       20|\n",
      "|  ham|Ok lar... Joking ...|        6|\n",
      "| spam|Free entry in 2 a...|       28|\n",
      "|  ham|U dun say so earl...|       11|\n",
      "|  ham|Nah I don't think...|       13|\n",
      "| spam|FreeMsg Hey there...|       32|\n",
      "|  ham|Even my brother i...|       16|\n",
      "|  ham|As per your reque...|       26|\n",
      "| spam|WINNER!! As a val...|       26|\n",
      "| spam|Had your mobile 1...|       29|\n",
      "|  ham|I'm gonna be home...|       21|\n",
      "| spam|SIX chances to wi...|       26|\n",
      "| spam|URGENT! You have ...|       26|\n",
      "|  ham|I've been searchi...|       37|\n",
      "|  ham|I HAVE A DATE ON ...|        8|\n",
      "| spam|XXXMobileMovieClu...|       19|\n",
      "|  ham|Oh k...i'm watchi...|        4|\n",
      "|  ham|Eh u remember how...|       19|\n",
      "|  ham|Fine if thatåÕs t...|       13|\n",
      "| spam|England v Macedon...|       24|\n",
      "+-----+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word count collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|word| count|\n",
      "+----+------+\n",
      "|    |784389|\n",
      "| the|282718|\n",
      "| and|194113|\n",
      "|  of|163358|\n",
      "|  to|145701|\n",
      "|   a|103066|\n",
      "|  in| 90602|\n",
      "|   I| 88815|\n",
      "|that| 72731|\n",
      "|  he| 53735|\n",
      "| his| 48351|\n",
      "|  it| 46497|\n",
      "|  as| 46428|\n",
      "|with| 45537|\n",
      "| was| 45149|\n",
      "|  is| 43232|\n",
      "| you| 42713|\n",
      "| for| 41989|\n",
      "|  my| 39440|\n",
      "|  be| 37498|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('word', f.explode(f.split(f.col('txt'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-6fdbd4a2ea9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df.withColumn('list', df['txt'].split(\" \")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = f.split(df['txt'], ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('NAME1', split_col.getItem(0))\n",
    "data = data.withColumn('NAME2', split_col.getItem(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------------+-------+\n",
      "|label|                 txt|              NAME1|  NAME2|\n",
      "+-----+--------------------+-------------------+-------+\n",
      "|  ham|Go until jurong p...|                 Go|  until|\n",
      "|  ham|Ok lar... Joking ...|                 Ok| lar...|\n",
      "| spam|Free entry in 2 a...|               Free|  entry|\n",
      "|  ham|U dun say so earl...|                  U|    dun|\n",
      "|  ham|Nah I don't think...|                Nah|      I|\n",
      "| spam|FreeMsg Hey there...|            FreeMsg|    Hey|\n",
      "|  ham|Even my brother i...|               Even|     my|\n",
      "|  ham|As per your reque...|                 As|    per|\n",
      "| spam|WINNER!! As a val...|           WINNER!!|     As|\n",
      "| spam|Had your mobile 1...|                Had|   your|\n",
      "|  ham|I'm gonna be home...|                I'm|  gonna|\n",
      "| spam|SIX chances to wi...|                SIX|chances|\n",
      "| spam|URGENT! You have ...|            URGENT!|    You|\n",
      "|  ham|I've been searchi...|               I've|   been|\n",
      "|  ham|I HAVE A DATE ON ...|                  I|   HAVE|\n",
      "| spam|XXXMobileMovieClu...|XXXMobileMovieClub:|     To|\n",
      "|  ham|Oh k...i'm watchi...|                 Oh|k...i'm|\n",
      "|  ham|Eh u remember how...|                 Eh|      u|\n",
      "|  ham|Fine if thatåÕs t...|               Fine|     if|\n",
      "| spam|England v Macedon...|            England|      v|\n",
      "+-----+--------------------+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|word| count|\n",
      "+----+------+\n",
      "|    |784389|\n",
      "| the|282718|\n",
      "| and|194113|\n",
      "|  of|163358|\n",
      "|  to|145701|\n",
      "|   a|103066|\n",
      "|  in| 90602|\n",
      "|   I| 88815|\n",
      "|that| 72731|\n",
      "|  he| 53735|\n",
      "| his| 48351|\n",
      "|  it| 46497|\n",
      "|  as| 46428|\n",
      "|with| 45537|\n",
      "| was| 45149|\n",
      "|  is| 43232|\n",
      "| you| 42713|\n",
      "| for| 41989|\n",
      "|  my| 39440|\n",
      "|  be| 37498|\n",
      "+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('word', f.explode(f.split(f.col('txt'), ' ')))\\\n",
    "    .groupBy('word')\\\n",
    "    .count()\\\n",
    "    .sort('count', ascending=False)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"../books/*.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6003218"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_file.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
